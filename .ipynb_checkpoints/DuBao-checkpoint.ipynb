{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NhietDoCao\n",
      "3\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-46af6c85935c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m#size = len(X) - 31 # Day last\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdistrict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'size' is not defined"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from math import sqrt, expm1\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import genfromtxt, savetxt\n",
    "\n",
    "def saveImage(y_true, y_pred, path,title):\n",
    "\tprint(y_true)\n",
    "\tx = range(1,len(y_true)+1)\n",
    "\tfig = plt.figure()\n",
    "\tplt.plot(x, y_true, label='Thuc Do'.format(i=1))\n",
    "\tplt.plot(x, y_pred,linestyle=\"--\", linewidth =2, label='Website'.format(i=2),color=\"red\")\n",
    "\tplt.legend(loc='best')\n",
    "\tplt.subplots_adjust(top=0.83)\n",
    "\tarrTitle = title.split(\",\")\n",
    "\tplt.title(title+\"\\n\")\n",
    "\tfig.savefig(path, dpi=fig.dpi*2)\n",
    "\n",
    "def dochinhxac(y_true,y_pred):\n",
    "\tresult = [];\n",
    "\tfor i in range(0,len(y_true)):\n",
    "\t\tif y_true[i] > 0:\n",
    "\t\t\tlech = abs(y_pred[i] - y_true[i])/y_true[i]\n",
    "\t\t\tresult.insert(0,1-lech)\n",
    "\treturn np.mean(result)\n",
    "\n",
    "def caculateIndex(arrPredict,test_y,dirPath = \"\",strDetail=\"\"):\n",
    "\tkey = 0;\n",
    "\tSum_ME = 0;\n",
    "\tSum_MEA = 0;\t\n",
    "\tSum_RMSE = 0;\t\t\n",
    "\tfor i in arrPredict:\n",
    "\t\t# caculate \n",
    "\t\tSum_ME += (arrPredict[key]-test_y[key])\n",
    "\t\t# (MAE)\n",
    "\t\tSum_MEA += abs(arrPredict[key]-test_y[key])\n",
    "\t\t#(RMSE):\n",
    "\t\tSum_RMSE += (arrPredict[key]-test_y[key])**2\n",
    "\t\tkey = key+1\n",
    "\tAVG_ME=Sum_ME/(key+1)\n",
    "\tAVG_MEA=Sum_MEA/(key+1)\n",
    "\tAVG_RMSE= sqrt(Sum_RMSE/(key+1))\n",
    "\tPercentChinhXac = dochinhxac(test_y,arrPredict)\n",
    "\tf= open(dirPath,\"w+\")\n",
    "\tf.write(\"%s, ME: %s,MEA: %s,RMSE: %s, Do Chinh Xac: %s\\n\" % (strDetail, AVG_ME,AVG_MEA,AVG_RMSE,PercentChinhXac))\n",
    "\tf.close()\n",
    "\t\n",
    "# Max Temperature\n",
    "arrDb = ['LuongMua','DoAm','NhietDoCao','MatTroi','NhietDoThap','Gio']\n",
    "arrAl = ['5,1,0','1,0,0','5,1,0','2,1,0','4,1,0','2,0,1']\n",
    "keyDb = 2\n",
    "nameDb = arrDb[keyDb]\n",
    "print(nameDb)\n",
    "month = 3\n",
    "print(month)\n",
    "for district in range(1,32):\n",
    "\tseries = read_csv('tempature_2019/'+str(month)+'.csv', header=-1, parse_dates=[0], index_col=0, squeeze=True)\n",
    "\tX = series.values\n",
    "\t#size = len(X) - 31 # Day last\n",
    "\ttrain = X[2:size,district]\n",
    "\thistory = train\n",
    "\tprint(history)\n",
    "\t#savetxt(\"Result/\"+nameDb+str(month)+\"_TrueValue.txt\", test, delimiter=',')\n",
    "\tpredictions = list()\n",
    "\thistory = [x for x in train]\n",
    "\tfor t in range(31):\n",
    "\t\tp,d,q = '5,1,0'.split(\",\")\n",
    "\t\tprint(history,np.array('5,1,0'.split(\",\")))\n",
    "\t\tmodel = ARIMA(history, order=(int(p),int(d),int(q)))\n",
    "\t\tmodel_fit = model.fit(disp=0)\n",
    "\t\toutput = model_fit.forecast()\n",
    "\t\tyhat = output[0]\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\thistory.append(obs)\n",
    "\t\tprint('predicted=%f, expected=%f' % (yhat, obs))\n",
    "\t#saveImage(test, predictions, \"Result/\"+nameDb+\"_\"+str(month)+\".png\",nameDb+\" Month:\"+str(month))\n",
    "\t#caculateIndex(predictions,test,\"Result/\"+nameDb+\".txt\",nameDb+\".txt\")\n",
    "\tpass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NhietDoCao\n",
      "3\n",
      "124\n",
      "predicted=28.625890]\n",
      "predicted=26.462202]\n",
      "predicted=29.870758]\n",
      "predicted=30.445018]\n",
      "predicted=26.568232]\n",
      "predicted=28.384913]\n",
      "predicted=28.830482]\n",
      "predicted=28.668340]\n",
      "predicted=28.005896]\n",
      "predicted=28.596392]\n",
      "predicted=26.082910]\n",
      "predicted=27.430020]\n",
      "predicted=29.990526]\n",
      "predicted=30.539689]\n",
      "predicted=28.111461]\n",
      "predicted=29.633706]\n",
      "predicted=28.242432]\n",
      "predicted=27.806923]\n",
      "predicted=29.575061]\n",
      "predicted=28.484349]\n",
      "predicted=28.839040]\n",
      "predicted=30.010286]\n",
      "predicted=29.837931]\n",
      "predicted=29.767321]\n",
      "predicted=26.857968]\n",
      "predicted=28.296055]\n",
      "predicted=28.648176]\n",
      "predicted=30.893980]\n",
      "predicted=27.245933]\n",
      "predicted=27.962398]\n",
      "predicted=27.895413]\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from math import sqrt, expm1\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import genfromtxt, savetxt\n",
    "\n",
    "def saveImage(y_true, y_pred, path,title):\n",
    "\tprint(y_true)\n",
    "\tx = range(1,len(y_true)+1)\n",
    "\tfig = plt.figure()\n",
    "\tplt.plot(x, y_true, label='Thuc Do'.format(i=1))\n",
    "\tplt.plot(x, y_pred,linestyle=\"--\", linewidth =2, label='Website'.format(i=2),color=\"red\")\n",
    "\tplt.legend(loc='best')\n",
    "\tplt.subplots_adjust(top=0.83)\n",
    "\tarrTitle = title.split(\",\")\n",
    "\tplt.title(title+\"\\n\")\n",
    "\tfig.savefig(path, dpi=fig.dpi*2)\n",
    "\n",
    "def dochinhxac(y_true,y_pred):\n",
    "\tresult = [];\n",
    "\tfor i in range(0,len(y_true)):\n",
    "\t\tif y_true[i] > 0:\n",
    "\t\t\tlech = abs(y_pred[i] - y_true[i])/y_true[i]\n",
    "\t\t\tresult.insert(0,1-lech)\n",
    "\treturn np.mean(result)\n",
    "\n",
    "def caculateIndex(arrPredict,test_y,dirPath = \"\",strDetail=\"\"):\n",
    "\tkey = 0;\n",
    "\tSum_ME = 0;\n",
    "\tSum_MEA = 0;\t\t\n",
    "\tSum_RMSE = 0;\t\t\n",
    "\tfor i in arrPredict:\n",
    "\t\t# caculate \n",
    "\t\tSum_ME += (arrPredict[key]-test_y[key])\n",
    "\t\t# (MAE)\n",
    "\t\tSum_MEA += abs(arrPredict[key]-test_y[key])\n",
    "\t\t#(RMSE):\n",
    "\t\tSum_RMSE += (arrPredict[key]-test_y[key])**2\n",
    "\t\tkey = key+1\n",
    "\tAVG_ME=Sum_ME/(key+1)\n",
    "\tAVG_MEA=Sum_MEA/(key+1)\n",
    "\tAVG_RMSE= sqrt(Sum_RMSE/(key+1))\n",
    "\tPercentChinhXac = dochinhxac(test_y,arrPredict)\n",
    "\twith open(dirPath, \"ab\") as myfile:\n",
    "\t\tmyfile.write(\"%s, ME: %s,MEA: %s,RMSE: %s, Do Chinh Xac: %s\\n\" % (strDetail, AVG_ME,AVG_MEA,AVG_RMSE,PercentChinhXac))\n",
    "# Date\n",
    "# Precipitation\n",
    "# Relative Humidity\n",
    "# Max Temperature\n",
    "# Solar\n",
    "# Min Temperature\n",
    "# Wind\n",
    "arrDb = ['LuongMua','DoAm','NhietDoCao','MatTroi','NhietDoThap','Gio']\n",
    "arrAl = ['5,1,0','1,0,0','5,1,0','2,1,0','4,1,0','2,0,1']\n",
    "nameDb = arrDb[keyDb];\n",
    "\n",
    "for district in range(1,25):\n",
    "    for month in range(3,4):\n",
    "        print(month)\n",
    "        series = read_csv('tempature_2019/'+str(month)+'.csv', header=-1, parse_dates=[0], index_col=0, squeeze=True)\n",
    "        X = series.values\n",
    "        train = X[0:len(X),district]\n",
    "        dataset = train\n",
    "        #savetxt(\"Result/\"+nameDb+str(month)+\"_TrueValue.txt\", test, delimiter=',')\n",
    "        predictions = list()\n",
    "        dataset = [x for x in train]\n",
    "        numYear = 4 \n",
    "        for t in range(31):\n",
    "            history = [];\n",
    "            for year in range(0,numYear):\n",
    "                #print(t+(year*31))\n",
    "                history.append(dataset[t+(year*31)])\n",
    "            model = ARIMA(history, order=(1,1,0))\n",
    "            model_fit = model.fit(disp=0)\n",
    "            output = model_fit.forecast()\n",
    "            yhat = output[0]\n",
    "            predictions.append(yhat[0])\n",
    "            history.append(yhat[0])\n",
    "            print('predicted=%f' % (yhat[0]))\n",
    "\n",
    "        #error = mean_squared_error(test, predictions)\n",
    "        #print('Test MSE: %.3f' % error)\n",
    "        savetxt(\"Result/\"+str(district)+\"_\"+str(month)+\".txt\", predictions, delimiter=',')\n",
    "        #saveImage(test, predictions, \"Result/\"+nameDb+\"_\"+str(month)+\".png\",nameDb+\" Month:\"+str(month))\n",
    "        #caculateIndex(predictions,test,\"Result/\"+nameDb+\".txt\",nameDb+\".txt\")\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31.75, 25.89, 28.46, 29.57]\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'subtract' did not contain a loop with signature matching types dtype('<U5') dtype('<U5') dtype('<U5')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-a558c31eea4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;31m#print(t+(year*31))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mARIMA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mmodel_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/statsmodels/tsa/arima_model.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, endog, order, exog, dates, freq, missing)\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mARIMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m             \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/statsmodels/tsa/arima_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, order, exog, dates, freq, missing)\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_unintegrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munintegrate_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m         \u001b[0;31m#NOTE: will check in ARMA but check again since differenced now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0m_check_estimable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mdiff\u001b[0;34m(a, n, axis)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnot_equal\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msubtract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types dtype('<U5') dtype('<U5') dtype('<U5')"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from math import sqrt, expm1\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import genfromtxt, savetxt\n",
    "\n",
    "def saveImage(y_true, y_pred, path,title):\n",
    "\tprint(y_true)\n",
    "\tx = range(1,len(y_true)+1)\n",
    "\tfig = plt.figure()\n",
    "\tplt.plot(x, y_true, label='Thuc Do'.format(i=1))\n",
    "\tplt.plot(x, y_pred,linestyle=\"--\", linewidth =2, label='Website'.format(i=2),color=\"red\")\n",
    "\tplt.legend(loc='best')\n",
    "\tplt.subplots_adjust(top=0.83)\n",
    "\tarrTitle = title.split(\",\")\n",
    "\tplt.title(title+\"\\n\")\n",
    "\tfig.savefig(path, dpi=fig.dpi*2)\n",
    "\n",
    "def dochinhxac(y_true,y_pred):\n",
    "\tresult = [];\n",
    "\tfor i in range(0,len(y_true)):\n",
    "\t\tif y_true[i] > 0:\n",
    "\t\t\tlech = abs(y_pred[i] - y_true[i])/y_true[i]\n",
    "\t\t\tresult.insert(0,1-lech)\n",
    "\treturn np.mean(result)\n",
    "\n",
    "def caculateIndex(arrPredict,test_y,dirPath = \"\",strDetail=\"\"):\n",
    "\tkey = 0;\n",
    "\tSum_ME = 0;\n",
    "\tSum_MEA = 0;\t\t\n",
    "\tSum_RMSE = 0;\t\t\n",
    "\tfor i in arrPredict:\n",
    "\t\t# caculate \n",
    "\t\tSum_ME += (arrPredict[key]-test_y[key])\n",
    "\t\t# (MAE)\n",
    "\t\tSum_MEA += abs(arrPredict[key]-test_y[key])\n",
    "\t\t#(RMSE):\n",
    "\t\tSum_RMSE += (arrPredict[key]-test_y[key])**2\n",
    "\t\tkey = key+1\n",
    "\tAVG_ME=Sum_ME/(key+1)\n",
    "\tAVG_MEA=Sum_MEA/(key+1)\n",
    "\tAVG_RMSE= sqrt(Sum_RMSE/(key+1))\n",
    "\tPercentChinhXac = dochinhxac(test_y,arrPredict)\n",
    "\twith open(dirPath, \"ab\") as myfile:\n",
    "\t\tmyfile.write(\"%s, ME: %s,MEA: %s,RMSE: %s, Do Chinh Xac: %s\\n\" % (strDetail, AVG_ME,AVG_MEA,AVG_RMSE,PercentChinhXac))\n",
    "# Date\n",
    "# Precipitation\n",
    "# Relative Humidity\n",
    "# Max Temperature\n",
    "# Solar\n",
    "# Min Temperature\n",
    "# Wind\n",
    "arrDb = ['LuongMua','DoAm','NhietDoCao','MatTroi','NhietDoThap','Gio']\n",
    "arrAl = ['5,1,0','1,0,0','5,1,0','2,1,0','4,1,0','2,0,1']\n",
    "nameDb = arrDb[keyDb];\n",
    "\n",
    "for district in range(0,24):\n",
    "    for month in range(4,5):\n",
    "        print(month, district)\n",
    "        series = read_csv('tempature_2019/'+str(month)+'.csv', header=-1, parse_dates=[0], index_col=0, squeeze=True)\n",
    "        X = series.values\n",
    "        train = X[0:len(X),district]\n",
    "        dataset = train\n",
    "        #savetxt(\"Result/\"+nameDb+str(month)+\"_TrueValue.txt\", test, delimiter=',')\n",
    "        predictions = list()\n",
    "        dataset = [x for x in train]\n",
    "        numYear = 4 \n",
    "        for t in range(31):\n",
    "            history = [];\n",
    "            for year in range(0,numYear):\n",
    "                #print(t+(year*31))\n",
    "                history.append(dataset[t+(year*31)])\n",
    "            model = ARIMA(history, order=(1,1,0))\n",
    "            model_fit = model.fit(disp=0)\n",
    "            output = model_fit.forecast()\n",
    "            yhat = output[0]\n",
    "            predictions.append(yhat[0])\n",
    "            history.append(yhat[0])\n",
    "            print('predicted=%f' % (yhat[0]))\n",
    "\n",
    "        #error = mean_squared_error(test, predictions)\n",
    "        #print('Test MSE: %.3f' % error)\n",
    "        savetxt(\"Result/\"+str(district)+\"_\"+str(month)+\".txt\", predictions, delimiter=',')\n",
    "        #saveImage(test, predictions, \"Result/\"+nameDb+\"_\"+str(month)+\".png\",nameDb+\" Month:\"+str(month))\n",
    "        #caculateIndex(predictions,test,\"Result/\"+nameDb+\".txt\",nameDb+\".txt\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X[0:len(X),0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0\n",
      "predicted=32.334179\n",
      "predicted=33.517297\n",
      "predicted=32.477681\n",
      "predicted=32.656844\n",
      "predicted=29.823099\n",
      "predicted=30.659993\n",
      "predicted=31.592492\n",
      "predicted=29.051028\n",
      "predicted=29.569355\n",
      "predicted=31.933111\n",
      "predicted=30.277628\n",
      "predicted=30.274590\n",
      "predicted=32.283513\n",
      "predicted=30.699844\n",
      "predicted=32.747929\n",
      "predicted=29.467522\n",
      "predicted=29.953359\n",
      "predicted=33.022075\n",
      "predicted=31.014976\n",
      "predicted=31.411604\n",
      "predicted=34.334741\n",
      "predicted=30.997992\n",
      "predicted=31.399379\n",
      "predicted=31.228952\n",
      "predicted=30.425986\n",
      "predicted=30.362080\n",
      "predicted=31.502505\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-b13ca2f57cd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumYear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;31m#print(t+(year*31))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mARIMA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mmodel_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from math import sqrt, expm1\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import genfromtxt, savetxt\n",
    "\n",
    "def saveImage(y_true, y_pred, path,title):\n",
    "\tprint(y_true)\n",
    "\tx = range(1,len(y_true)+1)\n",
    "\tfig = plt.figure()\n",
    "\tplt.plot(x, y_true, label='Thuc Do'.format(i=1))\n",
    "\tplt.plot(x, y_pred,linestyle=\"--\", linewidth =2, label='Website'.format(i=2),color=\"red\")\n",
    "\tplt.legend(loc='best')\n",
    "\tplt.subplots_adjust(top=0.83)\n",
    "\tarrTitle = title.split(\",\")\n",
    "\tplt.title(title+\"\\n\")\n",
    "\tfig.savefig(path, dpi=fig.dpi*2)\n",
    "\n",
    "def dochinhxac(y_true,y_pred):\n",
    "\tresult = [];\n",
    "\tfor i in range(0,len(y_true)):\n",
    "\t\tif y_true[i] > 0:\n",
    "\t\t\tlech = abs(y_pred[i] - y_true[i])/y_true[i]\n",
    "\t\t\tresult.insert(0,1-lech)\n",
    "\treturn np.mean(result)\n",
    "\n",
    "def caculateIndex(arrPredict,test_y,dirPath = \"\",strDetail=\"\"):\n",
    "\tkey = 0;\n",
    "\tSum_ME = 0;\n",
    "\tSum_MEA = 0;\t\t\n",
    "\tSum_RMSE = 0;\t\t\n",
    "\tfor i in arrPredict:\n",
    "\t\t# caculate \n",
    "\t\tSum_ME += (arrPredict[key]-test_y[key])\n",
    "\t\t# (MAE)\n",
    "\t\tSum_MEA += abs(arrPredict[key]-test_y[key])\n",
    "\t\t#(RMSE):\n",
    "\t\tSum_RMSE += (arrPredict[key]-test_y[key])**2\n",
    "\t\tkey = key+1\n",
    "\tAVG_ME=Sum_ME/(key+1)\n",
    "\tAVG_MEA=Sum_MEA/(key+1)\n",
    "\tAVG_RMSE= sqrt(Sum_RMSE/(key+1))\n",
    "\tPercentChinhXac = dochinhxac(test_y,arrPredict)\n",
    "\twith open(dirPath, \"ab\") as myfile:\n",
    "\t\tmyfile.write(\"%s, ME: %s,MEA: %s,RMSE: %s, Do Chinh Xac: %s\\n\" % (strDetail, AVG_ME,AVG_MEA,AVG_RMSE,PercentChinhXac))\n",
    "# Date\n",
    "# Precipitation\n",
    "# Relative Humidity\n",
    "# Max Temperature\n",
    "# Solar\n",
    "# Min Temperature\n",
    "# Wind\n",
    "arrDb = ['LuongMua','DoAm','NhietDoCao','MatTroi','NhietDoThap','Gio']\n",
    "arrAl = ['5,1,0','1,0,0','5,1,0','2,1,0','4,1,0','2,0,1']\n",
    "nameDb = arrDb[keyDb];\n",
    "\n",
    "for district in range(0,24):\n",
    "    for month in range(4,5):\n",
    "        print(month, district)\n",
    "        series = read_csv('tempature_2019/'+str(month)+'.csv', header=-1, parse_dates=[0], index_col=0, squeeze=True)\n",
    "        X = series.values\n",
    "        train = X[0:len(X),district]\n",
    "        dataset = train\n",
    "        #savetxt(\"Result/\"+nameDb+str(month)+\"_TrueValue.txt\", test, delimiter=',')\n",
    "        predictions = list()\n",
    "        dataset = [x for x in train]\n",
    "        numYear = 4 \n",
    "        for t in range(30):\n",
    "            history = [];\n",
    "            for year in range(0,numYear):\n",
    "                history.append(dataset[t+(year*30)])\n",
    "            model = ARIMA(history, order=(1,1,0))\n",
    "            model_fit = model.fit(disp=0)\n",
    "            output = model_fit.forecast()\n",
    "            yhat = output[0]\n",
    "            predictions.append(yhat[0])\n",
    "            history.append(yhat[0])\n",
    "            print('predicted=%f' % (yhat[0]))\n",
    "\n",
    "        #error = mean_squared_error(test, predictions)\n",
    "        #print('Test MSE: %.3f' % error)\n",
    "        savetxt(\"Result/\"+str(district)+\"_\"+str(month)+\".txt\", predictions, delimiter=',')\n",
    "        #saveImage(test, predictions, \"Result/\"+nameDb+\"_\"+str(month)+\".png\",nameDb+\" Month:\"+str(month))\n",
    "        #caculateIndex(predictions,test,\"Result/\"+nameDb+\".txt\",nameDb+\".txt\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
